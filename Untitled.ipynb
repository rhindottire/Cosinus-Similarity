{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "REGEX = re.compile(r\"\\s\")\n",
    "def tokenize(text):\n",
    "    return [tok.strip().lower() for tok in REGEX.split(text)]\n",
    "\n",
    "def stopwords(text):\n",
    "\treg = re.compile(r\"\\n\")\n",
    "\treturn reg.split(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file = open(\"source1.txt\",\"r\");\n",
    "raw1 = file.read()\n",
    "\n",
    "file = open(\"source2.txt\",\"r\");\n",
    "raw2 = file.read()\n",
    "\n",
    "file = open(\"source3.txt\",\"r\");\n",
    "raw3 = file.read()\n",
    "\n",
    "file = open(\"source4.txt\",\"r\");\n",
    "raw4 = file.read()\n",
    "\n",
    "file = open(\"source5.txt\",\"r\");\n",
    "raw5 = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# menghilangkan tanda baca\n",
    "tandabaca = [\".\",\",\",\"-\",\"%\"]\n",
    "for td in tandabaca:\n",
    "\traw1=raw1.replace(td,\"\")\n",
    "\traw2=raw2.replace(td,\"\")\n",
    "\traw3=raw3.replace(td,\"\")\n",
    "\traw4=raw4.replace(td,\"\")\n",
    "\traw5=raw5.replace(td,\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# menghilangkan stop words\n",
    "file = open(\"stopwords.txt\",\"r\");\n",
    "st = file.read()\n",
    "stopwords = stopwords(st)\n",
    "\n",
    "for word in stopwords:\n",
    "\traw1=raw1.replace(\" \"+word+\" \",\" \")\n",
    "\traw2=raw2.replace(\" \"+word+\" \",\" \")\n",
    "\traw3=raw3.replace(\" \"+word+\" \",\" \")\n",
    "\traw4=raw4.replace(\" \"+word+\" \",\" \")\n",
    "\traw5=raw5.replace(\" \"+word+\" \",\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# stemming \n",
    "factory = StemmerFactory()\n",
    "stemmer = factory.create_stemmer()\n",
    "\n",
    "\n",
    "hasilstem1 = stemmer.stem(raw1)\n",
    "hasilstem2 = stemmer.stem(raw2)\n",
    "hasilstem3 = stemmer.stem(raw3)\n",
    "hasilstem4 = stemmer.stem(raw4)\n",
    "hasilstem5 = stemmer.stem(raw5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#tokenization\n",
    "train_set = [hasilstem1,hasilstem2,hasilstem3,hasilstem4,hasilstem5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "count_vectorizer = CountVectorizer(tokenizer=tokenize)\n",
    "data = count_vectorizer.fit_transform(train_set).toarray()\n",
    "vocab = count_vectorizer.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jumlah Term FREQUENCY=============================\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 1]\n",
      " [0 1 1 ... 1 0 0]\n",
      " [0 0 0 ... 0 1 0]\n",
      " [1 0 1 ... 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Jumlah Term FREQUENCY=============================\")\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VECTOR FITUR=============================\n",
      "['1' '16' '2' '2019' '20192021' '2020' '2021' '2022' '22' '244' '2440'\n",
      " '2767' '33' '400' '88' '92' 'agung' 'ajar' 'akademik' 'akibat' 'alami'\n",
      " 'alhamdulillah' 'ambil' 'anak' 'anakanak' 'angka' 'apa' 'area' 'asing'\n",
      " 'aspek' 'asupan' 'badan' 'bahan' 'bahaya' 'bakar' 'balita' 'bangga'\n",
      " 'bangku' 'bbm' 'beberapa' 'beda' 'bensin' 'bersih' 'bisa' 'bkkbn' 'buka'\n",
      " 'buruk' 'campur' 'corporate' 'covid19' 'dampak' 'dari' 'dasar' 'data'\n",
      " 'degree' 'dengar' 'departemen' 'didik' 'double' 'dua' 'duduk' 'efek'\n",
      " 'endap' 'fakta' 'faktor' 'fungsi' 'gelar' 'gizi' 'hantu' 'harga' 'hasil'\n",
      " 'hasto' 'heboh' 'heppy' 'hukum' 'indonesia' 'infeksi' 'institusi'\n",
      " 'internasional' 'istilah' 'jakarta' 'jaksa' 'jenis' 'jenjang' 'jual'\n",
      " 'jurus' 'juta' 'kampus' 'kandung' 'karat' 'kebal' 'kejakgung' 'keluarga'\n",
      " 'kembang' 'kencana' 'kendara' 'kepala' 'khawatir' 'kilang' 'kok'\n",
      " 'kompascom' 'kondisi' 'konsumen' 'korupsi' 'kotor' 'kronis' 'kualitas'\n",
      " 'kuliah' 'kurang' 'kurun' 'kutip' 'label' 'lahir' 'laman' 'lemah' 'lho'\n",
      " 'mahasiswa' 'major' 'maksimal' 'malang' 'mampu' 'masa' 'masalah'\n",
      " 'masyaralat' 'mati' 'meni' 'mentah' 'mental' 'mesin' 'mesti' 'milik'\n",
      " 'minyak' 'miskin' 'modus' 'nahkirakira' 'nasional' 'negeri' 'ni' 'niaga'\n",
      " 'nikah' 'oplos' 'otak' 'pada' 'pandemi' 'panjang' 'pasang' 'pasar'\n",
      " 'pasuk' 'patra' 'pendek' 'performa' 'perintah' 'periode' 'persen'\n",
      " 'persentase' 'persentasi' 'persero' 'pertalite' 'pertama' 'pertamax'\n",
      " 'pertamina' 'pertatec' 'picu' 'postur' 'potensi' 'premium' 'produk'\n",
      " 'program' 'pt' 'pusat' 'rakernas' 'rencana' 'republikacoid' 'resiko'\n",
      " 'ribu' 'ron' 'rupa' 'rusa' 'saat' 'sama' 'sambut' 'sebab' 'secretary'\n",
      " 'sekitar' 'selasa' 'serius' 'sidi' 'sistem' 'sosioekonomi' 'ssgbi'\n",
      " 'statistik' 'status' 'studi' 'stunting' 'survei' 'syukur' 'tahun'\n",
      " 'tangan' 'tangki' 'tapi' 'tiap' 'tingkat' 'tubuh' 'tumbuh' 'turun'\n",
      " 'turut' 'universitas' 'usaha' 'usut' 'virtual' 'vs' 'wardoyo' 'warning'\n",
      " 'wulansari']\n"
     ]
    }
   ],
   "source": [
    "print(\"VECTOR FITUR=============================\")\n",
    "print(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JUMLAH VECTOR FITUR=============================\n",
      "214\n"
     ]
    }
   ],
   "source": [
    "print(\"JUMLAH VECTOR FITUR=============================\")\n",
    "print(len(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer().fit_transform(train_set)\n",
    "pairwise_similarity = tfidf * tfidf.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jumlah Term FREQUENCY-Inverse Document Frequency=============================\n",
      "<Compressed Sparse Row sparse matrix of dtype 'float64'\n",
      "\twith 246 stored elements and shape (5, 212)>\n",
      "  Coords\tValues\n",
      "  (0, 155)\t0.08143434842508683\n",
      "  (0, 157)\t0.16286869685017366\n",
      "  (0, 174)\t0.10093577586565702\n",
      "  (0, 197)\t0.10093577586565702\n",
      "  (0, 177)\t0.08143434842508683\n",
      "  (0, 170)\t0.10093577586565702\n",
      "  (0, 78)\t0.06759786545853118\n",
      "  (0, 37)\t0.10093577586565702\n",
      "  (0, 121)\t0.10093577586565702\n",
      "  (0, 70)\t0.10093577586565702\n",
      "  (0, 101)\t0.20187155173131405\n",
      "  (0, 129)\t0.24430304527526048\n",
      "  (0, 124)\t0.20187155173131405\n",
      "  (0, 21)\t0.08143434842508683\n",
      "  (0, 205)\t0.10093577586565702\n",
      "  (0, 166)\t0.4037431034626281\n",
      "  (0, 158)\t0.3257373937003473\n",
      "  (0, 154)\t0.10093577586565702\n",
      "  (0, 146)\t0.16286869685017366\n",
      "  (0, 136)\t0.16286869685017366\n",
      "  (0, 206)\t0.10093577586565702\n",
      "  (0, 164)\t0.10093577586565702\n",
      "  (0, 96)\t0.10093577586565702\n",
      "  (0, 131)\t0.10093577586565702\n",
      "  (0, 138)\t0.20187155173131405\n",
      "  :\t:\n",
      "  (4, 26)\t0.04921212032900189\n",
      "  (4, 77)\t0.04921212032900189\n",
      "  (4, 53)\t0.04921212032900189\n",
      "  (4, 27)\t0.04921212032900189\n",
      "  (4, 113)\t0.04921212032900189\n",
      "  (4, 20)\t0.14763636098700567\n",
      "  (4, 83)\t0.14763636098700567\n",
      "  (4, 132)\t0.04921212032900189\n",
      "  (4, 135)\t0.04921212032900189\n",
      "  (4, 108)\t0.04921212032900189\n",
      "  (4, 111)\t0.04921212032900189\n",
      "  (4, 204)\t0.09842424065800379\n",
      "  (4, 117)\t0.04921212032900189\n",
      "  (4, 190)\t0.04921212032900189\n",
      "  (4, 75)\t0.04921212032900189\n",
      "  (4, 81)\t0.04921212032900189\n",
      "  (4, 55)\t0.04921212032900189\n",
      "  (4, 25)\t0.04921212032900189\n",
      "  (4, 54)\t0.04921212032900189\n",
      "  (4, 64)\t0.04921212032900189\n",
      "  (4, 150)\t0.04921212032900189\n",
      "  (4, 16)\t0.04921212032900189\n",
      "  (4, 198)\t0.04921212032900189\n",
      "  (4, 85)\t0.04921212032900189\n",
      "  (4, 76)\t0.04921212032900189\n"
     ]
    }
   ],
   "source": [
    "print(\"Jumlah Term FREQUENCY-Inverse Document Frequency=============================\")\n",
    "print(tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jumlah COSINE-SIMILARITY=============================\n",
      "<Compressed Sparse Row sparse matrix of dtype 'float64'\n",
      "\twith 23 stored elements and shape (5, 5)>\n",
      "  Coords\tValues\n",
      "  (0, 3)\t0.027849404319431885\n",
      "  (0, 2)\t0.0033137880667345075\n",
      "  (0, 4)\t0.011927700903354021\n",
      "  (0, 1)\t0.2054787218211708\n",
      "  (0, 0)\t1.0\n",
      "  (1, 4)\t0.005272786736020421\n",
      "  (1, 2)\t0.011764223817362907\n",
      "  (1, 3)\t0.06812478933504837\n",
      "  (1, 1)\t0.9999999999999997\n",
      "  (1, 0)\t0.2054787218211708\n",
      "  (2, 3)\t0.21408219079755897\n",
      "  (2, 1)\t0.011764223817362907\n",
      "  (2, 4)\t0.006305214120519257\n",
      "  (2, 2)\t1.0000000000000004\n",
      "  (2, 0)\t0.0033137880667345075\n",
      "  (3, 2)\t0.21408219079755897\n",
      "  (3, 1)\t0.06812478933504837\n",
      "  (3, 3)\t0.9999999999999982\n",
      "  (3, 0)\t0.027849404319431885\n",
      "  (4, 1)\t0.005272786736020421\n",
      "  (4, 2)\t0.006305214120519257\n",
      "  (4, 4)\t0.9999999999999991\n",
      "  (4, 0)\t0.011927700903354021\n"
     ]
    }
   ],
   "source": [
    "print(\"Jumlah COSINE-SIMILARITY=============================\")\n",
    "print(pairwise_similarity)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
